<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<!-- Mirrored from www.digitalhumanities.org/dhq/vol/3/2/000041/000041.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 16 May 2015 13:06:38 GMT -->
<head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><title>DHQ: Digital Humanities Quarterly: Words, Patterns and Documents: Experiments in Machine Learning and Text Analysis</title><link rel="stylesheet" type="text/css" href="../../../../common/css/dhq.css"/><link rel="stylesheet" type="text/css" media="screen" href="../../../../common/css/dhq_screen.css"/><link rel="stylesheet" type="text/css" media="print" href="../../../../common/css/dhq_print.css"/><link rel="alternate" type="application/atom+xml" href="../../../../feed/news.xml"/><link rel="shortcut icon" href="../../../../common/images/favicon.ico"/><script type="text/javascript" src="../../../../common/js/javascriptLibrary.js">
                &lt;!-- Javascript functions --&gt;
            </script><script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-15812721-1']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
s.parentNode.insertBefore(ga, s);
 })();

        </script></head><body><div id="top"><div id="backgroundpic"><script type="text/javascript" src="../../../../common/js/pics.js"><!--displays banner image--></script></div><div id="banner"><div id="dhqlogo"><img src="http://www.digitalhumanities.org/dhq/common/images/dhqlogo.png" alt="DHQ Logo"/></div><div id="longdhqlogo"><img src="http://www.digitalhumanities.org/dhq/common/images/dhqlogolonger.png" alt="Digital Humanities Quarterly Logo"/></div></div><div id="topNavigation"><div id="topnavlinks"><span><a href="../../../../index.html" class="topnav">home</a></span><span><a href="../../../../submissions/index.html" class="topnav">submissions</a></span><span><a href="../../../../about/about.html" class="topnav">about dhq</a></span><span><a href="../../../../people/people.html" class="topnav">dhq people</a></span><span id="rightmost"><a href="../../../../contact/contact.html" class="topnav">contact</a></span></div><div id="search"><form action="http://www.digitalhumanities.org/dhq/findIt" method="get" onsubmit="javascript:document.location.href=cleanSearch(this.queryString.value); return false;"><div><input type="text" name="queryString" size="18"/> <input type="submit" value="Search"/></div></form></div></div></div><div id="main"><div id="leftsidebar"><div id="leftsidenav"><span>Current Issue<br/></span><ul><li><a href="../../../8/4/index.html">2014: 8.4</a></li></ul><span>Preview Issue<br/></span><ul><li><a href="../../../../preview/index.html">2015: 9.1</a></li></ul><span>Previous Issues<br/></span><ul><li><a href="../../../8/3/index.html">2014: 8.3</a></li><li><a href="../../../8/2/index.html">2014: 8.2</a></li><li><a href="../../../8/1/index.html">2014: 8.1</a></li><li><a href="../../../7/3/index.html">2013: 7.3</a></li><li><a href="../../../7/2/index.html">2013: 7.2</a></li><li><a href="../../../7/1/index.html">2013: 7.1</a></li><li><a href="../../../6/3/index.html">2012: 6.3</a></li><li><a href="../../../6/2/index.html">2012: 6.2</a></li><li><a href="../../../6/1/index.html">2012: 6.1</a></li><li><a href="../../../5/3/index.html">2011: 5.3</a></li><li><a href="../../../5/2/index.html">2011: 5.2</a></li><li><a href="../../../5/1/index.html">2011: 5.1</a></li><li><a href="../../../4/2/index.html">2010: 4.2</a></li><li><a href="../../../4/1/index.html">2010: 4.1</a></li><li><a href="../../4/index.html">2009: 3.4</a></li><li><a href="../../3/index.html">2009: 3.3</a></li><li><a href="../index.html">2009: 3.2</a></li><li><a href="../../1/index.html">2009: 3.1</a></li><li><a href="../../../2/1/index.html">2008: 2.1</a></li><li><a href="../../../1/2/index.html">2007: 1.2</a></li><li><a href="../../../1/1/index.html">2007: 1.1</a></li></ul><span>Indexes<br/></span><ul><li><a href="../../../../index/title.html"> Title</a></li><li><a href="../../../../index/author.html"> Author</a></li></ul></div><img src="http://www.digitalhumanities.org/dhq/common/images/lbarrev.png" style="margin-left : 7px;" alt="sidenavbarimg"/><div id="leftsideID"><b>ISSN 1938-4122</b><br/></div><div class="leftsidecontent"><h3>Announcements</h3><ul><li><a href="../../../../announcements/index.html#reviewers">Call for Reviewers</a></li><li><a href="../../../../announcements/index.html#submissions">Call for Submissions</a></li></ul></div><div class="leftsidecontent"><script type="text/javascript">addthis_pub  = 'dhq';</script><a href="http://www.addthis.com/bookmark.php" onmouseover="return addthis_open(this, '', '[URL]', '[TITLE]')" onmouseout="addthis_close()" onclick="return addthis_sendto()"><img src="http://s9.addthis.com/button1-addthis.gif" width="125" height="16" alt="button1-addthis.gif"/></a><script type="text/javascript" src="../../../../../../s7.addthis.com/js/152/addthis_widget.js">&lt;!-- Javascript functions --&gt;</script></div></div><div id="mainContent"><div id="printSiteTitle">DHQ: Digital Humanities Quarterly</div><div xmlns:dhqBiblio="http://digitalhumanities.org/dhq/ns/biblio" class="DHQarticle"><div id="pubInfo">2009<br/>Volume 3 Number 2</div><div class="toolbar"><form id="taporware" action="http://www.digitalhumanities.org/dhq/vol/3/2/000041/get"><div><a href="../index.html">2009 3.2</a>
                     | 
                    <a rel="external" href="000041.xml">XML</a>

| 
		   Discuss
			(<a href="000041.html#disqus_thread" data-disqus-identifier="000041">
				Comments
			</a>)
                </div></form></div><div class="DHQheader"><h1 class="articleTitle">Words, Patterns and Documents: Experiments in Machine Learning and Text Analysis</h1><div class="author"><a rel="external" href="../bios.html#argamon_s">Shlomo
    Argamon</a> &lt;<a href="mailto:argamon_at_iit_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('argamon_at_iit_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('argamon_at_iit_dot_edu'); return false;">argamon_at_iit_dot_edu</a>&gt;, Linguistic Cognition Lab, Dept. of Computer Science, Illinois Institute of Technology</div><div class="author"><a rel="external" href="../bios.html#olsen_m">Mark
    Olsen</a> &lt;<a href="mailto:markymaypo57_at_gmail_dot_com" onclick="javascript:window.location.href='mailto:'+deobfuscate('markymaypo57_at_gmail_dot_com'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('markymaypo57_at_gmail_dot_com'); return false;">markymaypo57_at_gmail_dot_com</a>&gt;, ARTFL Project, University of Chicago</div><span xmlns="" class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Words,%20Patterns%20and%20Documents%3A%20Experiments%20in%20Machine%20Learning%20and%20Text%20Analysis&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=2009-06-18&amp;rft.volume=003&amp;rft.issue=2&amp;rft.aulast=Argamon&amp;rft.aufirst=Shlomo&amp;rft.au=Shlomo%20Argamon&amp;rft.au=Mark%20Olsen"> </span></div><div id="DHQtext"><div class="counter"><a href="#p1">1</a></div><div class="ptext" id="p1">One of the emerging grand challenges for digital humanities in the next decade is to address rapidly expanding repositories of electronic text.  A number of efforts, such as <a class="ref" href="http://books.google.com/" onclick="window.open('http://books.google.com/'); return false">Google Book Search</a> and the <a class="ref" href="http://theeuropeanlibrary.org/" onclick="window.open('http://theeuropeanlibrary.org/'); return false">Bibliothèque numérique européenne</a>, are digitizing the holdings of many of the world's great research libraries.  The resulting collections will contain nothing less than, in Gregory Crane's view, the "stored record of humanity" [<a class="ref" href="#crane2006">Crane 2006</a>].  This expansion beyond existing digital collections will be one of at least a couple of orders of magnitude, and will introduce a variety of new problems beyond simply scale, including heterogeneity of content and granularity of objects.   The problems posed by the emerging global digital library offer opportunities for collaborative work between scholars in the humanities and computer scientists in many domains, from optical character and page recognition to historical ontologies [<a class="ref" href="#argamon2006">Argamon and Olsen 2006</a>].  The papers presented here reflect initial collaborative work between the ARTFL Project at the University of Chicago and the Linguistic Cognition Laboratory at the Illinois Institute of Technology on one subset of the technologies required for a future global digital library: the intersection of machine learning, text mining and text analysis.</div><div class="counter"><a href="#p2">2</a></div><div class="ptext" id="p2">Traditional models of text analysis in digital humanities have concentrated on searching for a relatively small number of words and reporting results in formats long familiar to humanities scholars, most notably concordances, collocation tables, and word frequency breakdowns.<a class="noteRef" href="#d35633e96">[1]</a>  While effective for many types of questions, this approach will not scale effectively beyond collections of a relatively modest size, as result sets for even uncommon groups of words will balloon to a size not readily digestible by humans.  Furthermore, this approach does not lend itself to abstract discussions of entire works, the oeuvre of an author or period, or issues related to the language of gender, genre, or ethnicity. It places the onus on the user to construct queries and assimilate results, without leveraging the capacity of machines to identify patterns in massive amount of data.</div><div class="counter"><a href="#p3">3</a></div><div class="ptext" id="p3">Machine learning and text mining approaches appear to offer a compelling complement to
    traditional text analysis, by having the computer sift through massive amounts of text looking for "suggestive patterns."  The power of modern machine learning systems to uncover patterns in large amounts of data has led to their widespread use in many applications, from spam filters to analyzing genetic sequences.  And the potential for using these sophisticated algorithms to find meaningful patterns in humanistic texts has been recently observed.  Drawing a link between Ian Witten's general description of data mining and the practice of literary criticism, Stephen Ramsay states that "[f]inding interesting patterns and regularities in data is generally held to be of the deepest significance." Any such findings must be approached with critical prudence, he warns, as they will contain "the spurious, the contingent, the inexact, the imperfect, and the accidental in a state of almost guaranteed incompleteness" [<a class="ref" href="#ramsay2005">Ramsay 2005</a>, 186]. Ramsay is quite correct to point out both the potential power and pitfalls of applying text mining to questions in the humanities.   Our current work is to design sets of relatively constrained experiments using text mining systems on specific problems in order to examine what works, what does not work, and just what such results might mean.</div><div class="counter"><a href="#p4">4</a></div><div class="ptext" id="p4">To this end, the ARTFL Project has developed a set of machine learning extensions to PhiloLogic, our full-text search and analysis system.<a class="noteRef" href="#d35633e117">[2]</a>  PhiloMine replaces the notion of "searching" a database for one or more words with "task" submission.   We currently view three broad classes of "tasks": predictive text mining, comparative text mining, and clustering/similarity analysis.  Predictive mining approaches are widely used in applications such as spam e-mail filters, which are trained on samples of spam and non-spam messages and used to identify incoming junk mail.  This supervised learning technique can be applied to a wide variety of tasks, such as learning on topically classified articles in the <cite class="title italic">Encyclopédie</cite> and assigning these classes to unclassified articles or parts of other documents.  It is common in digital humanities to work with corpora where many classifications, such as gender or nationality of author, are already known.  In this case, machine learning algorithms may be used to compare texts based on different attributes.  For example, one may compare works by American and non-American Black playwrights, returning measures of how well the classification task was performed, identifying incorrectly classified documents, and the features (often words) most characteristic of the distinction.   Finally, document similarity and clustering is an unsupervised form of machine learning, designed to identify groups of documents statistically that share common features.  We are using nearest neighbor document similarity, for example, to identify passages in one text that may have been copied from an earlier document.</div><div class="counter"><a href="#p5">5</a></div><div class="ptext" id="p5">The three papers which follow use all three approaches to attempt to shed light on specific research questions in the humanities.  "Gender, Race, and Nationality..." examines how well machine learning tools can isolate stylistic or content features of authors and characters by gender, race, and nationality in a large collection of works by Black playwrights.  In general, the classification results on a range of mining tasks were quite good, suggesting that these techniques can effectively distinguish, for example, the writing of male and female or American and non-American authors.  In some cases, the results provide insight into the texts as literary works, but in others we found the intellectual value of the feature sets to be less interesting. We also found that, while classifying texts under binary oppositions is generally effective for the machine learning algorithms employed, doing so tends to reduce complex works and corpora to very limited sets of common features.</div><div class="counter"><a href="#p6">6</a></div><div class="ptext" id="p6">In "Vive la différence...", we examine a single binary classification, on gender of author in French literature predominantly from the 17th to the early 20th centuries. Using balanced male and female corpora, we found substantial agreement with Olsen's previous studies of gendered writing in published works, with our results supporting his observation of a more personal and emotional sphere of female authorship. Our results also comport with Argamon's previous work (with Koppel) on the British National Corpus, where female writing was found to be characterized by more frequent use of personal pronouns, with male writing characterized by more frequent use of determiners and numerical quantifiers. Additionally, a number of strong thematic groups of content words were found for both genders that were consistently useful in classification across the time period represented in the corpus, suggesting some enduring differences between male and female writing in the corpus.</div><div class="counter"><a href="#p7">7</a></div><div class="ptext" id="p7">The third paper, "Mining Eighteenth Century Ontologies...",  uses predictive classification to examine the ontology of Diderot and d'Alembert's <cite class="title italic">Encyclopédie</cite>. Our initial experiments attempting to classify the unclassified articles of the Encyclopédie led us to reconsider the coherency of the editors' classification scheme and overall distribution of classes in the entire work.   Lastly, applying this ontology of the classes of knowledge to the <cite class="title italic">Journal de Trévoux</cite>, an 18th century scholarly journal, we were able to make several new connections between the two corpora that went previously unnoticed.</div><div class="counter"><a href="#p8">8</a></div><div class="ptext" id="p8">The power of machine learning and text mining applications to detect patterns is clearly demonstrated in these papers, yet several issues arose during this work which we believe should be raised.  The first is the surprisingly small size of the patterns detected.  In all of the experiments, the systems dutifully created models to fit classes, but these were often based on quite tiny fractions of all of the available features -- a mere 60 surface words can adequately distinguish hundreds of American and non-American plays by black authors.   Similarly, we find that for both predictive classification and clustering tasks, the number of features for most tasks used is a tiny fraction of all possible features.   Resulting features may well reflect a "lowest common denominator" which, while perfectly adequate for specific mining tasks, may not be as useful in characterizing works in an intellectually satisfying fashion. The fact that our studies examining the issue of gendered writing arrived at similar conclusions regarding the differences between male and female writing and characterizations may thus in part be an artifact of the way learners and classifiers function. Finally, our classification tasks are generally considered to have produced a significant result when we achieve an accuracy of 70% or more, although the most successful tasks can surpass 95%.  When examining the features most useful to the model, we must not assume that their importance holds for the documents whose class could not be predicted; indeed, their incorrect classification suggests that these documents may have quite different patterns of word usage.</div><div class="counter"><a href="#p9">9</a></div><div class="ptext" id="p9">The "lowest common denominator" problem would also appear to be related to a second concern which may be specific to machine learning on humanities texts. By treating relatively small numbers of documents with very large numbers of possible features, classifiers are thus given a wide range of features to accomplish any particular task.  While we used different techniques to validate results, including n-fold cross validation and random falsification, there would appear to be some danger of obtaining results based on the construction of the task itself.  Even if significant results are found, showing, e.g. that classification by a particular binary opposition can be performed reliably at 80% accuracy, in itself this says little about the underlying phenomenon under investigation.  A binary opposition that is thus "empirically supported" may well be an epiphenomenon that is merely correlated with another underlying complex of causes, which remain to be teased out.  So finding such "statistical patterns" is, ultimately, merely the first step in what must be a critically well-grounded argument, supported also by evidence external to the classification results themselves.</div><div class="counter"><a href="#p10">10</a></div><div class="ptext" id="p10">To help us argue for the general efficacy of machine learning approaches and address the concerns set forth above, we include a reaction piece by Sean Meehan, who writes about the anxieties of doing criticism by algorithm. Meehan raises the issue of distance in any critical endeavor, pointing out that interpretive analysis is always "a dynamic between tools and texts." In the end, he sounds the theme of scholarly circumspection and care that we try to bring out in all of the articles. Using machine learning tools on humanities texts requires the same understanding of the texts and degree of self-awareness that are necessary for any literary critical study.</div><div class="counter"><a href="#p11">11</a></div><div class="ptext" id="p11">As we hope these small scale experiments have demonstrated, text mining and machine learning algorithms offer novel ways to approach problems of text analysis and interpretation.  One can pose questions of many hundreds or thousands of documents and obtain results that are interesting and sometimes even striking.  It further seems clear that text mining will be a powerful technology deployed in order to make the emerging global digital library manageable and meaningful.</div></div><div id="notes"><h2>Notes</h2><div class="endnote" id="d35633e96"><span class="noteRef">[1]</span>The PhiloLogic text search and analysis package, developed at ARTFL, is one of many examples of such traditionally oriented systems. Documentation, downloads and samples are available at <a class="ref" href="http://philologic.uchicago.edu/" onclick="window.open('http://philologic.uchicago.edu/'); return false">http://philologic.uchicago.edu/</a>.</div><div class="endnote" id="d35633e117"><span class="noteRef">[2]</span>See <a class="ref" href="http://philologic.uchicago.edu/philomine/" onclick="window.open('http://philologic.uchicago.edu/philomine/'); return false">http://philologic.uchicago.edu/philomine/</a> for samples, documentation, and downloads.  Not all machine learning and text mining tasks in the following papers used Philomine.</div></div><div id="worksCited"><h2>Works Cited</h2><div class="bibl fallback"><span class="ref" id="argamon2006"><!-- close -->Argamon and Olsen 2006</span> Argamon, Shlomo and Olsen, Mark, "Toward meaningful computing," in <cite class="title italic">Communications of the Association for Computing Machinery</cite> 49:4 (2006), 33-35.</div><div class="bibl fallback"><span class="ref" id="crane2006"><!-- close -->Crane 2006</span> Crane, Gregory, "What Do You Do with with a Million Books" in  <cite class="title italic">D-Lib Magazine</cite>  12:3 (March 2006)  [doi:10.1045/march2006-crane].</div><div class="bibl fallback"><span class="ref" id="ramsay2005"><!-- close -->Ramsay 2005</span> Ramsay, Stephen, "In Praise of Pattern,"<cite class="title italic">Text Technology</cite> 2 (2005).</div></div><div class="toolbar"><a href="../index.html">2009 3.2</a>
             | 
            <a rel="external" href="000041.xml">XML</a>
            | 
            <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div></div><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script><div id="comments"><div id="disqus_thread"/><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    // The following are highly recommended additional parameters. Remove the slashes in front to use.
    var disqus_identifier = '000041';
    var disqus_url = '000041.html';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><div id="footer"> 
            URL: http://www.digitalhumanities.org/dhq/vol/3/2/000041/000041.html<br/>Last updated:
            <script type="text/javascript">
                var monthArray = new initArray("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December");
                var lastModifiedDate = new Date(document.lastModified);
                var currentDate = new Date();
                document.write(" ",monthArray[(lastModifiedDate.getMonth()+1)]," ");
                document.write(lastModifiedDate.getDate(),", ",(lastModifiedDate.getFullYear()));
            </script><br/> Comments: <a href="mailto:dhqinfo@digitalhumanities.org" class="footer">dhqinfo@digitalhumanities.org</a><br/> Published by:
            <a href="http://www.digitalhumanities.org/" class="footer">The Alliance of Digital Humanities Organizations</a><br/>Affiliated with: <a href="http://llc.oxfordjournals.org/">Literary and Linguistic Computing</a><br/> Copyright 2005 - <script type="text/javascript">
                document.write(currentDate.getFullYear());</script><br/> This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative Commons
                    Attribution-Noncommercial-No Derivative Works 3.0 License</a><br/><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png"/></a></div></div></div></body>
<!-- Mirrored from www.digitalhumanities.org/dhq/vol/3/2/000041/000041.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 16 May 2015 13:06:39 GMT -->
</html>