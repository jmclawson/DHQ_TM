<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<!-- Mirrored from www.digitalhumanities.org/dhq/vol/3/1/000027/000027.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 16 May 2015 13:06:59 GMT -->
<head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><title>DHQ: Digital Humanities Quarterly: Digitizing Latin Incunabula:  Challenges, Methods, and Possibilities</title><link rel="stylesheet" type="text/css" href="../../../../common/css/dhq.css"/><link rel="stylesheet" type="text/css" media="screen" href="../../../../common/css/dhq_screen.css"/><link rel="stylesheet" type="text/css" media="print" href="../../../../common/css/dhq_print.css"/><link rel="alternate" type="application/atom+xml" href="../../../../feed/news.xml"/><link rel="shortcut icon" href="../../../../common/images/favicon.ico"/><script type="text/javascript" src="../../../../common/js/javascriptLibrary.js">
                &lt;!-- Javascript functions --&gt;
            </script><script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-15812721-1']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
s.parentNode.insertBefore(ga, s);
 })();

        </script></head><body><div id="top"><div id="backgroundpic"><script type="text/javascript" src="../../../../common/js/pics.js"><!--displays banner image--></script></div><div id="banner"><div id="dhqlogo"><img src="http://www.digitalhumanities.org/dhq/common/images/dhqlogo.png" alt="DHQ Logo"/></div><div id="longdhqlogo"><img src="http://www.digitalhumanities.org/dhq/common/images/dhqlogolonger.png" alt="Digital Humanities Quarterly Logo"/></div></div><div id="topNavigation"><div id="topnavlinks"><span><a href="../../../../index.html" class="topnav">home</a></span><span><a href="../../../../submissions/index.html" class="topnav">submissions</a></span><span><a href="../../../../about/about.html" class="topnav">about dhq</a></span><span><a href="../../../../people/people.html" class="topnav">dhq people</a></span><span id="rightmost"><a href="../../../../contact/contact.html" class="topnav">contact</a></span></div><div id="search"><form action="http://www.digitalhumanities.org/dhq/findIt" method="get" onsubmit="javascript:document.location.href=cleanSearch(this.queryString.value); return false;"><div><input type="text" name="queryString" size="18"/> <input type="submit" value="Search"/></div></form></div></div></div><div id="main"><div id="leftsidebar"><div id="leftsidenav"><span>Current Issue<br/></span><ul><li><a href="../../../8/4/index.html">2014: 8.4</a></li></ul><span>Preview Issue<br/></span><ul><li><a href="../../../../preview/index.html">2015: 9.1</a></li></ul><span>Previous Issues<br/></span><ul><li><a href="../../../8/3/index.html">2014: 8.3</a></li><li><a href="../../../8/2/index.html">2014: 8.2</a></li><li><a href="../../../8/1/index.html">2014: 8.1</a></li><li><a href="../../../7/3/index.html">2013: 7.3</a></li><li><a href="../../../7/2/index.html">2013: 7.2</a></li><li><a href="../../../7/1/index.html">2013: 7.1</a></li><li><a href="../../../6/3/index.html">2012: 6.3</a></li><li><a href="../../../6/2/index.html">2012: 6.2</a></li><li><a href="../../../6/1/index.html">2012: 6.1</a></li><li><a href="../../../5/3/index.html">2011: 5.3</a></li><li><a href="../../../5/2/index.html">2011: 5.2</a></li><li><a href="../../../5/1/index.html">2011: 5.1</a></li><li><a href="../../../4/2/index.html">2010: 4.2</a></li><li><a href="../../../4/1/index.html">2010: 4.1</a></li><li><a href="../../4/index.html">2009: 3.4</a></li><li><a href="../../3/index.html">2009: 3.3</a></li><li><a href="../../2/index.html">2009: 3.2</a></li><li><a href="../index.html">2009: 3.1</a></li><li><a href="../../../2/1/index.html">2008: 2.1</a></li><li><a href="../../../1/2/index.html">2007: 1.2</a></li><li><a href="../../../1/1/index.html">2007: 1.1</a></li></ul><span>Indexes<br/></span><ul><li><a href="../../../../index/title.html"> Title</a></li><li><a href="../../../../index/author.html"> Author</a></li></ul></div><img src="http://www.digitalhumanities.org/dhq/common/images/lbarrev.png" style="margin-left : 7px;" alt="sidenavbarimg"/><div id="leftsideID"><b>ISSN 1938-4122</b><br/></div><div class="leftsidecontent"><h3>Announcements</h3><ul><li><a href="../../../../announcements/index.html#reviewers">Call for Reviewers</a></li><li><a href="../../../../announcements/index.html#submissions">Call for Submissions</a></li></ul></div><div class="leftsidecontent"><script type="text/javascript">addthis_pub  = 'dhq';</script><a href="http://www.addthis.com/bookmark.php" onmouseover="return addthis_open(this, '', '[URL]', '[TITLE]')" onmouseout="addthis_close()" onclick="return addthis_sendto()"><img src="http://s9.addthis.com/button1-addthis.gif" width="125" height="16" alt="button1-addthis.gif"/></a><script type="text/javascript" src="../../../../../../s7.addthis.com/js/152/addthis_widget.js">&lt;!-- Javascript functions --&gt;</script></div></div><div id="mainContent"><div id="printSiteTitle">DHQ: Digital Humanities Quarterly</div><div xmlns:dhqBiblio="http://digitalhumanities.org/dhq/ns/biblio" class="DHQarticle"><div id="pubInfo">Changing the Center of Gravity: Transforming Classical Studies Through
      Cyberinfrastructure<br/>2009<br/>Volume 3 Number 1</div><div class="toolbar"><form id="taporware" action="http://www.digitalhumanities.org/dhq/vol/3/1/000027/get"><div><a href="../index.html">2009 3.1</a>
                     | 
                    <a rel="external" href="000027.xml">XML</a>

| 
		   Discuss
			(<a href="000027.html#disqus_thread" data-disqus-identifier="000027">
				Comments
			</a>)
                </div></form></div><div class="DHQheader"><h1 class="articleTitle">Digitizing Latin Incunabula:  Challenges, Methods, and Possibilities</h1><div class="author"><a rel="external" href="../bios.html#rydberg-cox_j">Jeffrey A. Rydberg-Cox</a> &lt;<a href="mailto:rydbergcoxj_at_umkc_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('rydbergcoxj_at_umkc_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('rydbergcoxj_at_umkc_dot_edu'); return false;">rydbergcoxj_at_umkc_dot_edu</a>&gt;, University of Missouri-Kansas City</div><span xmlns="" class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Digitizing%20Latin%20Incunabula%3A%20Challenges,%20Methods,%20and%20Possibilities&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=2009-02-26&amp;rft.volume=003&amp;rft.issue=1&amp;rft.aulast=Rydberg-Cox&amp;rft.aufirst=Jeffrey A.&amp;rft.au=Jeffrey A.%20Rydberg-Cox"> </span></div><div id="DHQtext"><div id="abstract"><h2>Abstract</h2><p>Incunabula, or books printed before 1500, are extremely difficult and expensive to
               convert to digital form.  The primary challenges arise from the use of non-standard typographical glyphs based on medieval handwriting to abbreviate words.  Further difficulties are also posed by the practice of inconsistently marking word breaks at the end of lines and reducing or even eliminating spacing between some words. As such, these documents form a distinct genre of electronic document that poses unique challenges for conversion to digital form.   From 2005–2007, the Preservation and Access Research and Development Program at the National Endowment for the Humanities funded a study to explore methods for digitizing these difficult texts.  This paper describes some of the results of that project. <a class="noteRef" href="#d38522e72">[1]</a></p></div><div class="div div0"><h1 class="head">Introduction</h1><div class="counter"><a href="#p1">1</a></div><div class="ptext" id="p1">Incunabula and other early printed works pose intriguing challenges and test cases for large-scale mass digitization projects such as Google Books<a class="noteRef" href="#d38522e90">[2]</a> and the Open Content Alliance.<a class="noteRef" href="#d38522e93">[3]</a>  While there are many different challenges related to the digitization of early printed books such as encoding layout information, marginalia, hand-added marks to denote the structure of works, etc., the project described here focused on only one class of problem.  Our primary aim was to study the challenges associated with representing in digital form the complex and non-standard typefaces used in these texts to abbreviate words in imitation of of medieval handwriting practice.  Although there are many different types of abbreviation, the most prevalent is the use of a macron over vowels to indicate the removal of the subsequent nasal consonant<a class="noteRef" href="#d38522e98">[4]</a>.  These glyphs can represent different sets of characters in different contexts.  For example, the string "ê" can be used to designate "en" or "em", while a stylized variations on the letter "q" can denote many different common Latin words such as "que" and "quod", and stylized variations of the letter "p" to denote the common prefixes "per" or "pro". There are also specialized characters for some very common words.</div><div id="figure01" class="figure"><div class="ptext"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure01.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure01.jpg" alt="Sample brevigraphs from early Latin books"/></a></div><div class="caption"><div class="label">Figure 1. </div>Sample Brevigraphs</div></div><div class="counter"><a href="#p2">2</a></div><div class="ptext" id="p2">In addition to non-standard glyphs, two other early modern typographical practices make incunabula difficult to digitize.  First, word divisions or spaces between words are often unclear; it can be difficult for data entry contractors to tell where one word begins and the next word ends.</div><div class="counter"><a href="#p3">3</a></div><div id="figure02" class="figure"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure02.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure02.jpg" alt="Sample Unclear Word Division from early Latin books"/></a><div class="caption"><div class="label">Figure 2. </div>Sample Unclear Word Division</div></div><div class="counter"><a href="#p4">4</a></div><div class="ptext" id="p4">Second, words often break across line endings without hyphenation or any other mark.  For example, the first three characters of a word can appear on one line with the final three characters on the following line and no typographical indicator of the word break.  This practice can vary from line to line within a text; one line may be hyphenated while the next line will have a word break that is not hyphenated.</div><div id="figure03" class="figure"><div class="ptext"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure03.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure03.jpg" alt="Sample word break across line ending from early Latin books"/></a></div><div class="caption"><div class="label">Figure 3. </div>Sample word break across line ending</div></div><div class="counter"><a href="#p5">5</a></div><div class="ptext" id="p5">These examples of the most common abbreviations only begin to describe an extremely complex typographic system.  For example, the 1488 edition of the <cite class="title italic">Stultifera Navis</cite> was printed using some 168 unique glyphs while Pincius’ 1497 Latin translation of Diogenes’ <cite class="title italic">Vitae et Sententiae Philosophorum</cite> contains some 156 unique glyphs.  With the additional complexities introduced by varying practices from press to press across Europe and even among compositors at a single press, the number of possible variations expands exponentially.  </div><div class="counter"><a href="#p6">6</a></div><div class="ptext" id="p6">These features of early typography occur at varying rates in different texts, but
               they appear so frequently in every early printed text that any digitization project must try to account for their presence.  For example, the Archimedes Digital Library Project to digitize important early printed source texts for studying the history of mechanics created a library of sixty texts printed between the years 1495 and 1691.<a class="noteRef" href="#d38522e164">[5]</a>  In this broad corpus of texts, on average there are three to five abbreviations on every page.  As one moves earlier in the history of print, abbreviations become much more common and correspondingly more difficult to deal with.  For example, the Stultifera Navis (1488) has 313 pages and 12,404 abbreviations, an average of 39.8 abbreviations per page; the <cite class="title italic">Legenda Aurea</cite> (before 1478) has 829 pages and 120,261 abbreviations, an average of 145 abbreviations per page; and the <cite class="title italic">Vitae et Sententiae Philosophorum</cite> (1497) has 190 pages and 52,267 abbreviations, an average of 276 abbreviations per page. </div><div class="counter"><a href="#p7">7</a></div><div class="ptext" id="p7">Because of the prevalence of these glyphs, incunabula cannot be processed using OCR software.  Commercial OCR programs produce almost no recognizable character strings, let alone searchable text.  Sravana Reddy and Greg Crane have shown that ABBY FineReader can recognize only 84% of the glyphs on a page and that the open source GAMERA system can be trained to recognize only 80% of the glyphs in texts from our testbed [<a class="ref" href="#reddy2006">Reddy 2006</a>]. Other methods must be explored.</div></div><div class="div div0"><h1 class="head">Methods</h1><div class="counter"><a href="#p8">8</a></div><div class="ptext" id="p8">When considering methods for digitizing early printed books, it is first essential to ask how much functionality end-users require from a digital facsimile of an incunable and study how much human intervention is required to create a text that end-users might find usable.  We evaluated the costs and added value associated with different approaches to digitizing these documents.  These approaches can be roughly organized into five groups:</div><div class="ptext"><ul class="list"><li class="item"><span class="label bold">Image Books:</span>  Image books are simply page images that are scanned
                  or photographed and placed online.  A user can browse the pages sequentially, but there is no text to be searched — only images to be viewed.  </li><li class="item"><span class="label bold">Image Books With Minimal Structural Data:</span>  This structural data includes section headers, chapter headings, indexes, et cetera.  These allow for some navigation of the text, but still not full text searching.  </li><li class="item"><span class="label bold">Image Front Transcriptions:</span>  Image front transcriptions were pioneered by  projects such as Making of America at the University of Michigan and Cornell.  In this format, page images are run through an optical character recognition process and then the uncorrected OCR is used for searching, but the end user is only ever presented with the page image.  This means that some of the benefits of searchability are made available to the end user while not incurring the expense of actually going through and cleaning up the OCR text to a point where it would be presentable to a human user.</li><li class="item"><span class="label bold">Carefully Edited and Tagged Transcriptions:</span>  These sorts of texts are the kind that you might find in a digital library such as Bartleby or the Perseus Project.  These are texts that exist in the public domain that have been typed or processed via OCR. A scholar carefully checks the text against the original to make sure it is accurate and places it online.  Generally, these texts are marked up in XML (projects that began before the creation of XML might also have texts in SGML).  These texts are also marked up according to a DTD  such as DocBook or the Text Encoding Initiative.  </li><li class="item"><span class="label bold">Scholarly and Critical Editions:</span>  These digital texts replicate the work that scholars have done with printed text for hundreds of years.  Scholars will choose an author, examine all his or her works, study all the variants and create an authoritative version of a text.  They will replicate in digital form all of the standard footnotes and critical apparatus that one would expect in a printed scholarly edition of a text.  </li></ul></div><div class="counter"><a href="#p9">9</a></div><div class="ptext" id="p9">In our project, we initially planned to create tagged transcriptions of many different sample texts.  As we considered these different genres, we decided that it would be much more interesting to create sample texts in each of these genres except for a full scholarly critical edition. This would allow us to see and evaluate first hand the costs and benefits of the different approaches.  We created image books of Petrarch's 1492 De Remediis Utriusque Fortunae  (Cremona, Bernardinus de Misintis and Caesar Parmensis;  text images provided  courtesy of National Library of Medicine) and Isidore of Seville's 1472 Etymologiae Liber IX (Ausberg, Gunther Zainer; text images provided courtesy of National Library of Medicine).  We created image books with minimal structural data of Pliny the Elder's 1472  Naturalis Historiae Liber (Venice,  Nicolas Jenson; text images provided courtesy of Linda Hall Library).   We created image front transcriptions of Sebastian Brant's 1488 Ship of Fools (Lyons, Jaques Sacon; text images provided courtesy of Harvard University Countway Library)  and Jacobus de Voragine's pre-1478 Legenda Aurea (Ulm, Johann Zainer; text images provided courtesy of Conception Abbey Seminary Library).    We carefully transcribed and edited Suetonius' 1494 Vitae XII Caesarum (Milan, Leonard Pachel text images provided courtesy of Conception Abbey Seminary Library) and Diogenes Laertius' 1497 Latin translation of the  Lives of Eminent Philosophers (Philippus Pincius for Benedictus Fontana; text images provided courtesy of the Universiyt of Missouri Kansas City Libraries.)</div><div class="counter"><a href="#p10">10</a></div><div class="ptext" id="p10">As one moves from image books to critical editions, the cost of the digital facsimile predictably increases because each element of human intervention introduces new costs.  Capturing an image is  the least expensive minimum baseline that all other editions build on; structural metadata adds human labor and expense beyond the cataloging of each image.  Assuming that a text is amenable to OCR, image front transcriptions are only slightly more expensive and might even be cheaper than image books with manually created minimal structural metadata.  The creation of a scholarly or critical edition lies at the other end of the cost spectrum; this is the sort of work that might take many years or even represent a scholar's lifetime achievement.  The biggest jump in cost comes in the move from an image front transcription to a carefully edited and tagged transcription.  Although preparing a page for OCR adds additional labor, manual data entry costs substantially more; when an editorial team must also be paid, costs escalate rapidly.</div><div class="counter"><a href="#p11">11</a></div><div class="ptext" id="p11">It is least expensive, of course, to produce digital images of a book and not provide
               any searchable text; the ability to search a text, however, is such an important
               function for most users that the extra labor and expense is justified.  An optimial compromise between cost and functionality seems to emerge in the image-front model pioneered by projects such as the Making of America and now being implemented on a broad scale by Google Book Search and the Open Content Alliance.   This approach is successful because it allows for the cost-effective digitization of large numbers of books while also providing the functionality and readabilty that most users expect.  Indeed, most people who use digital texts expect to be able to search them, but they are not necessarily displeased to find a page image as opposed to a typed text transcription.  While the findings of Reddy and Crane show that incunabula cannot yet be processed using this sort of workflow, these large scale projects are extremely intriguing.  Ultimately, if the problems of typography and layout can be resoloved to the point that these texts can be processed automatically, it would be possible to imagine the creation of similarly large corpora of early printed books.</div><div class="counter"><a href="#p12">12</a></div><div class="ptext" id="p12">The image-front approach to digitizing modern books should be applicable to early printed books because many of the high cost components are the same regardless of the source text.  The Open Content Alliance claims that their method has moved costs from twenty dollars per page to ten cents per page.  In our project, we had similar costs; when creating a human-edited searchable transcriptions, we spent between twenty and thirty-five dollars per page.  These costs broke down as follows.  We spent between two and ten dollars for each photograph of a page.  The cost here depended primarily on the physical location of the book.  Many of the books that we photographed in this project were physically located at libraries in Washington, D.C. and Boston,  so we had to factor in our travel expenses for those images.  We were able to photograph the books located in Kansas City for roughly two dollars per page.  We then paid two dollars to six dollars per page to create character sets and to have the text typed.  We paid one dollar and twenty-five cents per megabyte and used character sets to identify the unusual and non-standard characters that the data entry contractors encountered.  In general, we found that it was possible for a human to edit the transcriptions and expand the abbreviations at a rate of two pages per hour.  In our work, each page was checked twice resulting in a cost of ten to twelve dollars per page for tagging and proofreading.  To this must be added supervision, training and project administrative costs, and institutional overhead rates.  In order to reduce these costs and enable large scale digitization projects for early printed works, the primary aim must be to reduce tagging and proofreading costs.  Because of the fragile nature of early printed books, manual photographers cannot be replaced by robotic scanners, but even with this expense our work suggests that it should be possible to create an image-front edition for somewhere between five and six dollars per page.</div></div><div class="div div0"><h1 class="head">Data Entry Methodology</h1><div class="counter"><a href="#p13">13</a></div><div class="ptext" id="p13">Once the decision has been made to digitize the text rather than displaying page images or page images with minimal metadata, the next issue to be faced is how to address the numerous characters and glyphs that cannot be represented in current computer encoding systems including Unicode.  It was necessary, therefore, for us to develop a method that data entry contractors could use to represent these characters as they were typing our texts. 
    The data entry process begins with a manually created catalog of every brevigraph that appears
    in each printed book (illustrated in <a href="#figure04">Figure 4</a>).</div><div id="figure04" class="figure"><div class="ptext"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure04.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure04.jpg" alt="Sample Catalog of Brevigraphs"/></a></div><div class="caption"><div class="label">Figure 4. </div>Sample Catalog of Brevigraphs</div></div><div class="counter"><a href="#p14">14</a></div><div class="ptext" id="p14">  In this process, a unique entity identifier is assigned to each non-standard character that data entry personnel use to represent that glyph in a text.  For example, the opening lines of the 1494 edition of Suetonius’ Vitae XII Caesarum is printed as follows: <div id="figure05" class="figure"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure05.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure05.jpg" alt="Sample Lines from Suetonius.  Vitae XII Caesarum.  Milan: Leonard Pachel. 1494 "/></a><div class="caption"><div class="label">Figure 5. </div>Sample Lines from Suetonius.  <cite class="title italic">Vitae XII Caesarum.</cite>  Milan: Leonard Pachel. 1494 </div></div></div><div class="counter"><a href="#p15">15</a></div><div class="ptext" id="p15">Using the catalog of brevigraphs, this line would have been entered by data entry contractors as follows:</div><div class="counter"><a href="#p16">16</a></div><div class="ptext" id="p16"><span class="monospace">patr&amp;e1; amisit sequ&amp;e2;tibus&amp;q1; co&amp;c1;sulibus flamen dialis destinatus</span></div><div class="counter"><a href="#p17">17</a></div><div class="ptext" id="p17">If the goal of this process is to create a carefully tagged TEI-conformant text that reflects the typography of a printed page, this product of raw data entry could be tagged as followed using the TEI abbr tag from the TEI P4 guidelines to represent each different glyph<a class="noteRef" href="#d38522e245">[6]</a>.  </div><div class="counter"><a href="#p18">18</a></div><div class="ptext" id="p18"><span class="monospace">patre&lt;abbr type='e1'&gt;m&lt;/abbr&gt; amisit; seque&lt;abbr type='e2'&gt;n&lt;/abbr&gt;ntibus&lt;abbr type='q1'&gt;que&lt;/abbr&gt; co&lt;abbr type='c1'&gt;n&lt;/abbr&gt;sulibus flamen dialis destinatus</span></div></div><div class="div div0"><h1 class="head">Possibilities</h1><div class="counter"><a href="#p19">19</a></div><div class="ptext" id="p19">Because the expansion of these abbreviations is an extremely time-consuming and painstaking task, we developed three tools to facilitate the tagging process.  These tools suggest possible expansions for Latin abbreviations and brevigraphs, help identify words that are divided across lines, and separate words that are joined as the results of irregular spacing.  All three programs can return results in HTML for human readability or by XML in response to remote procedure call as part of a program to automatically expand abbreviations in these texts.</div><div class="counter"><a href="#p20">20</a></div><div class="ptext" id="p20">The abbreviation expansion tool uses regular expressions to search all attested Latin forms in the Packard Humanities Institute Database of Latin, the Perseus Digital Library and our collection of texts.  The program can return results in HTML for human readability or by XML in response to remote procedure call so that texts can be automatically tagged. </div><div id="figure06" class="figure"><div class="ptext"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure06.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure06.jpg" alt="Abbreviation Expansion Tool"/></a></div><div class="caption"><div class="label">Figure 6. </div>Abbreviation Expansion Tool</div></div><div class="counter"><a href="#p21">21</a></div><div class="ptext" id="p21">The unmarked word break tool takes broken words and searches that same lexical database for possible word combinations.  This tool also provides its results by HTML and XML.  </div><div id="figure07" class="figure"><div class="ptext"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure07.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure07.jpg" alt="Unmarked Word Break Tool"/></a></div><div class="caption"><div class="label">Figure 7. </div>Unmarked Word Break Tool</div></div><div class="counter"><a href="#p22">22</a></div><div class="ptext" id="p22">Finally, the unclear word division tool takes a string and breaks it into pieces and searches for combinations that match attested forms in our lexical database and once again, the interface is provided for human readability in HTML and for use by a remote procedure call via XML.</div><div id="figure08" class="figure"><div class="ptext"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure08.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure08.jpg" alt="Unclear Word Division Tool"/></a></div><div class="caption"><div class="label">Figure 8. </div>Unclear Word Division Tool</div></div><div class="counter"><a href="#p23">23</a></div><div class="ptext" id="p23">The results are sorted by frequency to provide the editor with a sense of the most likely result.  Although we conducted some experiments to see if n-grams or Hidden Markov Models can provide better weightings than raw frequencies, they did not provide more usable results for human editors.  If we were to move to fully automatic expansion of these abbreviations, these weighting techinques would come into play.  </div></div><div class="div div0"><h1 class="head">Conclusion</h1><div class="counter"><a href="#p24">24</a></div><div class="ptext" id="p24">Our work on this project suggests that it is possible to begin to conceive of a large-scale project to create image front editions of early printed texts with uncorrected manual data entry available for searching.  The biggest expense in our workflow lies in the cost of having a human editor tag the abbreviations and a second editor proofread that work.  Clearly, these costs can be reduced by creating image front editions on the model of the Open Content Alliance or the Google Book project.   It would be necessary for us to replace the uncorrected OCR in their workflow with the uncorrected manually typed text from our workflow.  Users could then search this uncorrected text and actually read from the page image.   Because of the high rate of abbreviation, there is a price to be paid in terms of search precision.  However, the precision/recall trade-off would not be such that it would render the text unusable.  In the texts we studied for the NEH project, some 45-50% of words have no brevigraphs or abbreviations and another 25% of the abbreviations can be unambiguously expanded into a single word.  The decrease in precision is introduced in the remaining 25%; of these, 10% have two or three expansions, 7.5% have more than three expansions, and 7.5% cannot be resolved.  These numbers suggest that there would be a substantial increase in precision over recall for only a small percentage of searches.  These results suggest that it would be possible to use these tools to create image front transcriptions.  We could use our tools to automatically correct our transcriptions and perhaps have a single human editor check the corrections at a rate of four to five pages per hour.  End-users would be able to search this transcription and read the page images.  </div><div class="counter"><a href="#p25">25</a></div><div class="ptext" id="p25">While this approach advances our ability to undertake a large scale project to digitize early printed books, there is still some missing functionality.  One of the advantages of a transcribed text is the ability to create automatic hypertexts.  For many years, the Perseus Digital Library has used its morphological analysis engine to create texts that are automatically annotated with morphological and syntactic data.  In the Perseus interface, a user can click on a word to discover its part of speech and the lexical forms from which it could be derived.  The interface also provides links to dictionaries and grammars that facilitate further inquiry.<a class="noteRef" href="#d38522e292">[7]</a></div><div id="figure09" class="figure"><div class="ptext"><a href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure09.jpg" rel="external"><img src="http://www.digitalhumanities.org/dhq/vol/3/1/000027/resources/images/figure09.jpg" alt="Sample Interface Showing Page Image and Transcription with Morphological Links"/></a></div><div class="caption"><div class="label">Figure 9. </div>Sample Interface Showing Page Image and Transcription with Morphological Links</div></div><div class="counter"><a href="#p26">26</a></div><div class="ptext" id="p26">These tools allow student and scholars to read texts in the original Greek or Latin even if they do not have expert knowledge of these languages.  These tools would be particularly useful for early printed books because these texts are essential for the study of almost every aspect of early modern culture.  Many of them, however, have not been translated and many scholars who study this period are not afforded expert training in all of the languages that they may need to utilize to study this period.  </div><div class="counter"><a href="#p27">27</a></div><div class="ptext" id="p27">The addition of this functionality might justify the substantial additional cost of creating a transcribed text.  It also creates a compelling question for our research.  If our image front transcription could also contain pixel coordinates for individual words, it would be possible to access the automatic hypertext via the page image.  Users could click on the page image to see the raw text, the automatic expansions suggested by our tools and also the morphological and syntactic information from the Perseus morphological analyzer.  This model is slightly more expensive than one where texts are just searched, but the image is not clickable.  The data entry costs must increase because the typist will capture the pixel coordinates for each word.  At the same time, however, editorial costs will fall because the transcription will only be used for searching with the word coordinates used for morphology and, in fact, we would hope that the text could come back from our data entry contractor and be used almost as is with minimal human intervention.  </div><div class="counter"><a href="#p28">28</a></div><div class="ptext" id="p28">How do we analyze the costs and benefits of this approach?  The idea of "just in
            time conversion" provides us with the best model for analysis.  John Price
               Wilkins, in a 1997 article entitled "Just in Time Conversion,
               Just in Case Collections," argues that digital library usage patterns
               mirror those of traditional libraries.<a class="noteRef" href="#d38522e318">[8]</a>  In this usage pattern, many materials can sit unused for very long periods of time punctuated by a period of high and intensive use. This pattern holds in the digital collections we have created for other projects.  In some semesters, many texts will not be used at all, but one or two will be used very intensively.  To the extent that this pattern holds larger collections of lightly edited text seem to provide more benefits to a broader audience than smaller collections of closely edited transcriptions or critical editions.</div><div class="counter"><a href="#p29">29</a></div><div class="ptext" id="p29">Further, using this model does not preclude the creation of a more carefully edited transcription or critical edition.  Rather, it can provide the foundation for these texts.  In this model, the raw or lightly corrected text can be provided to scholars with the expertise and inclination to create a more carefully edited version.  This text could be released under a Creative Commons license that requires that the improved text to be returned to the scholarly community.  For example, we could initially publish an uncorrected image front edition of the Legenda Aurea.  A scholar working with this text could download the uncorrected transcription and devote their expertise to creating a better electronic transcription of the text.  Under the Creative Commons license, they could use this as they wished and they would also return it to us and, ultimately, improve the entire digital library.  </div></div></div><div id="notes"><h2>Notes</h2><div class="endnote" id="d38522e72"><span class="noteRef">[1]</span>The work described in this paper was completed by the "Approaching the Problems of Digitizing Latin Incunables" project funded by the National Endowment for the Humanities Division of Preservation and Access. The material in this paper is drawn from the project application, internal technical reports, grant project reports and the project descriptions included in <span class="error"><a class="ref" href="#rydberg-cox2003">#rydberg-cox2003</a></span> and <span class="error"><a class="ref" href="#rydberg-cox2005">#rydberg-cox2005</a></span>. Much of this work was inspired by Ross Scaife and his work building a corpora of Latin Colloquia. I am deeply grateful for Ross's comments, advice and support. A version of this paper will also be published as part of the project web site.</div><div class="endnote" id="d38522e90"><span class="noteRef">[2]</span>[<a class="ref" href="#googlebooks">Google Books</a>]</div><div class="endnote" id="d38522e93"><span class="noteRef">[3]</span>[<a class="ref" href="#opencontent">Open Content</a>]; [<a class="ref" href="#bbc2005">BBC 2005</a>]</div><div class="endnote" id="d38522e98"><span class="noteRef">[4]</span>This discussion appeared in the original proposal, and was summarized in <span class="error"><a class="ref" href="#rydberg-cox2005">#rydberg-cox2005</a></span></div><div class="endnote" id="d38522e164"><span class="noteRef">[5]</span>[<a class="ref" href="#archimedes">Archimedes</a>]; [<a class="ref" href="#archimedestemplates">Archimedes Templates</a>]</div><div class="endnote" id="d38522e245"><span class="noteRef">[6]</span>When this project was planned in 2004, we based our work on the TEI P4 guidelines and elected to use the <span class="monospace">abbr</span> tag in our work.  The new TEI P5 standard released in November of 2007 now has much more complete guidelines for working with character sets that are not represented in the Unicode standard.  Although these guidelines appeared too late to inform the work of this project, the guidelines would need to be incorporated into any further work on these documents.</div><div class="endnote" id="d38522e292"><span class="noteRef">[7]</span><a class="ref" href="http://www.perseus.tufts.edu/" onclick="window.open('http://www.perseus.tufts.edu/'); return false">http://www.perseus.tufts.edu</a>; [<a class="ref" href="#crane1998">Crane 1998</a>]; [<a class="ref" href="#crane1991">Crane 1991</a>].</div><div class="endnote" id="d38522e318"><span class="noteRef">[8]</span><span class="error"><a class="ref" href="#price-wilkin1997">#price-wilkin1997</a></span></div></div><div id="worksCited"><h2>Works Cited</h2><div class="bibl fallback"><span class="ref" id="archimedes"><!-- close -->Archimedes</span> <a class="ref" href="http://archimedes.fas.harvard.edu/" onclick="window.open('http://archimedes.fas.harvard.edu/'); return false">http://archimedes.fas.harvard.edu/</a>.</div><div class="bibl fallback"><span class="ref" id="archimedestemplates"><!-- close -->Archimedes Templates</span> <a class="ref" href="http://zope.mpiwg-berlin.mpg.de/archimedes/archimedes_templates" onclick="window.open('http://zope.mpiwg-berlin.mpg.de/archimedes/archimedes_templates'); return false">http://zope.mpiwg-berlin.mpg.de/archimedes/archimedes_templates</a>.</div><div class="bibl fallback"><span class="ref" id="bbc2005"><!-- close -->BBC 2005</span> "Microsoft scans British Library BBC news online," November 4, 2005 <a class="ref" href="http://news.bbc.co.uk/2/hi/technology/4402442.stm" onclick="window.open('http://news.bbc.co.uk/2/hi/technology/4402442.stm'); return false">http://news.bbc.co.uk/2/hi/technology/4402442.stm</a>.</div><div class="bibl fallback"><span class="ref" id="crane1991"><!-- close -->Crane 1991</span> Crane, G. "Generating and Parsing Classical Greek."<cite class="title italic">Literary and Linguistic Computing</cite> 6 (1991): 243-245.</div><div class="bibl fallback"><span class="ref" id="crane1998"><!-- close -->Crane 1998</span> Crane, G. "New Technologies for Reading: The Lexicon and the Digital Library."<cite class="title italic">Classical World</cite> (1998): 471-501.</div><div class="bibl fallback"><span class="ref" id="googlebooks"><!-- close -->Google Books</span> <a class="ref" href="http://books.google.com/" onclick="window.open('http://books.google.com/'); return false">http://books.google.com/</a>.</div><div class="bibl fallback"><span class="ref" id="opencontent"><!-- close -->Open Content</span> <a class="ref" href="http://www.opencontentalliance.org/" onclick="window.open('http://www.opencontentalliance.org/'); return false">http://www.opencontentalliance.org</a>.</div><div class="bibl fallback"><span class="ref" id="pricewilkin1997"><!-- close -->Price-Wilkin 1997</span> Price-Wilkin, John. "Just-in-time Conversion, Just-in-case Collections: Effectively leveraging rich document formats for the WWW."<cite class="title italic">D-Lib Magazine</cite>, May 1997, <a class="ref" href="http://www.dlib.org/dlib/may97/michigan/05pricewilkin.html" onclick="window.open('http://www.dlib.org/dlib/may97/michigan/05pricewilkin.html'); return false">http://www.dlib.org/dlib/may97/michigan/05pricewilkin.html</a>.</div><div class="bibl fallback"><span class="ref" id="reddy2006"><!-- close -->Reddy 2006</span>  Reddy, Sravana, and Gregory Crane. "A Document Recognition System for Early Modern Latin." In <cite class="title italic">Chicago Colloquium on Digital Humanities and Computer Science: What Do You Do With A Million Books</cite> (DHCS 2006), Chicago, Illinois: University of Chicago, 2006.</div><div class="bibl fallback"><span class="ref" id="rydbergcox2003"><!-- close -->Rydberg-Cox 2003</span>  Rydberg-Cox, Jeffrey A. "Automatic Disambiguation of Latin Abbreviations in Early Modern Texts for Humanities Digital Libraries". <cite class="title italic">Proceedings of the 2003 Joint Conference on Digital Libraries</cite>, 372-373.</div><div class="bibl fallback"><span class="ref" id="rydbergcox2005"><!-- close -->Rydberg-Cox 2005</span>  Rydberg-Cox, Jeffrey A. <cite class="title italic">Digital Libraries and the Challenges of Digital Humanities</cite>. Chandos Press, October 2005: 39-43.</div><div class="bibl fallback"><span class="ref" id="seattle2005"><!-- close -->Seattle 2005</span> "Alliance Aims to Digitize Classic Books,"<cite class="title italic">Seattle Times Books Section,</cite> Monday, October 24, 2005.</div></div><div class="toolbar"><a href="../index.html">2009 3.1</a>
             | 
            <a rel="external" href="000027.xml">XML</a>
            | 
            <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div></div><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script><div id="comments"><div id="disqus_thread"/><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    // The following are highly recommended additional parameters. Remove the slashes in front to use.
    var disqus_identifier = '000027';
    var disqus_url = '000027.html';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><div id="footer"> 
            URL: http://www.digitalhumanities.org/dhq/vol/3/1/000027/000027.html<br/>Last updated:
            <script type="text/javascript">
                var monthArray = new initArray("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December");
                var lastModifiedDate = new Date(document.lastModified);
                var currentDate = new Date();
                document.write(" ",monthArray[(lastModifiedDate.getMonth()+1)]," ");
                document.write(lastModifiedDate.getDate(),", ",(lastModifiedDate.getFullYear()));
            </script><br/> Comments: <a href="mailto:dhqinfo@digitalhumanities.org" class="footer">dhqinfo@digitalhumanities.org</a><br/> Published by:
            <a href="http://www.digitalhumanities.org/" class="footer">The Alliance of Digital Humanities Organizations</a><br/>Affiliated with: <a href="http://llc.oxfordjournals.org/">Literary and Linguistic Computing</a><br/> Copyright 2005 - <script type="text/javascript">
                document.write(currentDate.getFullYear());</script><br/> This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative Commons
                    Attribution-Noncommercial-No Derivative Works 3.0 License</a><br/><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png"/></a></div></div></div></body>
<!-- Mirrored from www.digitalhumanities.org/dhq/vol/3/1/000027/000027.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 16 May 2015 13:07:00 GMT -->
</html>